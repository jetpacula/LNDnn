{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ucs08zzxJgUg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from skimage.color import rgba2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "with open('data.zip', 'wb') as f:\n",
    "    s3.download_fileobj('intelinair-data-releases', 'longitudinal-nutrient-deficiency/Longitudinal_Nutrient_Deficiency.zip', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip -qq ./data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_RfHjvrNCi1",
    "outputId": "3a078454-0aa4-4593-a274-230d7fa4cc06"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bfk8o2imLY98",
    "outputId": "cb318451-fa05-4ea9-b32a-b1eb1b569447"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n",
    "\n",
    "tb = SummaryWriter(comment='myboard')\n",
    "\n",
    "# Device configuration\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlmfGMJL-7h_"
   },
   "source": [
    "## Готовим датасет\n",
    "\n",
    "Скачиваем данные, передаем трансформер (предобработку), визуализируем  примеры семплов, создаем dataloaders для обучения и тестирования модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "s1BPUh3WIZr0"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "     #   self.img_labels = os.walk(self.img_dir)][1:]\n",
    "        self.img_labels = [x[0]+\"/nutrient_mask_g0.png\" for x in os.walk(datasetDir)][1:]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "     #   lst = [x[0] for x in os.walk(datasetDir)][1:][]\n",
    "      #  folder_list = [x[0] for x in os.walk(self.img_dir)][1:]\n",
    "#pil_image = PIL.Image.open('Image.jpg').convert('RGB') \n",
    "\n",
    "        image = PIL.Image.open(os.path.join(datasetDir, \"field_\"+\"{:03d}\".format(idx+1)+\"/image_i0.png\")).convert('RGB') #убираем ф\n",
    "        label =  PIL.Image.open(os.path.join(datasetDir, \"field_\"+\"{:03d}\".format(idx+1)+\"/nutrient_mask_g0.png\")).convert('1')\n",
    "   #     image = rgba2rgb(PIL.Image.open(os.path.join(datasetDir, \"field_\"+\"{:03d}\".format(idx+1)+\"/image_i0.png\")))\n",
    "    #    label =  rgba2rgb(PIL.Image.open(os.path.join(datasetDir, \"field_\"+\"{:03d}\".format(idx+1)+\"/nutrient_mask_g0.png\")))\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)#[:,:,:3]\n",
    "            label = self.transform(label)#[:,:,:3]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tiRn0fHSDEc9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "datasetDir = os.path.join(os.getcwd(),'Longitudinal_Nutrient_Deficiency')\n",
    "mydataset = CustomDataset(img_dir = datasetDir, transform = transforms.Compose([transforms.Resize(480), transforms.CenterCrop(480),transforms.ToTensor()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "rZvNZEXcsOAx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, testing_data = train_test_split(mydataset, test_size=0.2, random_state=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zU5w1N2WA2pv"
   },
   "outputs": [],
   "source": [
    "train_loader =  torch.utils.data.DataLoader(training_data, \n",
    "                                          batch_size=40, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1)\n",
    "    \n",
    "test_loader = torch.utils.data.DataLoader(testing_data, \n",
    "                                          batch_size=40, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBMfWnwhArnK",
    "outputId": "859e820d-2ad9-4566-d75e-3029d63d49a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 3, 480, 480]), torch.Size([40, 1, 480, 480]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_loader))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SmwoODZ3F1Y-"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = self.contract_block(in_channels, 32, 7, 3)\n",
    "        self.conv2 = self.contract_block(32, 64, 3, 1)\n",
    "        self.conv3 = self.contract_block(64, 128, 3, 1)\n",
    "\n",
    "        self.upconv3 = self.expand_block(128, 64, 3, 1)\n",
    "        self.upconv2 = self.expand_block(64*2, 32, 3, 1)\n",
    "        self.upconv1 = self.expand_block(32*2, out_channels, 3, 1)\n",
    "\n",
    "    def __call__(self, x):\n",
    "\n",
    "        # downsampling part\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "\n",
    "        upconv3 = self.upconv3(conv3)\n",
    "\n",
    "        upconv2 = self.upconv2(torch.cat([upconv3, conv2], 1))\n",
    "        upconv1 = self.upconv1(torch.cat([upconv2, conv1], 1))\n",
    "\n",
    "        return upconv1\n",
    "\n",
    "    def contract_block(self, in_channels, out_channels, kernel_size, padding):\n",
    "\n",
    "        contract = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "                                 )\n",
    "\n",
    "        return contract\n",
    "\n",
    "    def expand_block(self, in_channels, out_channels, kernel_size, padding):\n",
    "\n",
    "        expand = nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
    "                            torch.nn.BatchNorm2d(out_channels),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
    "                            torch.nn.BatchNorm2d(out_channels),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1) \n",
    "                            )\n",
    "        return expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNET(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GgQ36a9DHh2q"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def train(model, train_dl, valid_dl, loss_fn, optimizer, acc_fn, epochs=1):\n",
    "    start = time.time()\n",
    "    model.cpu()\n",
    "\n",
    "    train_loss, valid_loss = [], []\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set trainind mode = true\n",
    "                dataloader = train_dl\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "                dataloader = valid_dl\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "\n",
    "            step = 0\n",
    "\n",
    "            # iterate over data\n",
    "            for x, y in dataloader:\n",
    "                x = x.cpu()\n",
    "                y = y.cpu()\n",
    "                step += 1\n",
    "\n",
    "                # forward pass\n",
    "                if phase == 'train':\n",
    "                    # zero the gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(x)\n",
    "                    from IPython.core.debugger import Tracer\n",
    "                  #  Tracer()() # на loss валится\n",
    "                    \n",
    "                    loss = loss_fn(outputs, y)\n",
    "                    \n",
    "\n",
    "                    # the backward pass frees the graph memory, so there is no \n",
    "                    # need for torch.no_grad in this training pass\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    # scheduler.step()\n",
    "\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(x)\n",
    "                        loss = loss_fn(outputs, y.long())\n",
    "\n",
    "                # stats - whatever is the phase\n",
    "                acc = acc_fn(outputs, y)\n",
    "\n",
    "                running_acc  += acc*dataloader.batch_size\n",
    "                running_loss += loss*dataloader.batch_size \n",
    "\n",
    "              #  if step % 10 == 0:\n",
    "                    # clear_output(wait=True)\n",
    "           #         print('Current step: {}  Loss: {}  Acc: {}  AllocMem (Mb): {}'.format(step, loss, acc, torch.cuda.memory_allocated()/1024/1024))\n",
    "                    # print(torch.cuda.memory_summary())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_acc / len(dataloader.dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
    "    \n",
    "    return train_loss, valid_loss    \n",
    "\n",
    "def acc_metric(predb, yb):\n",
    "    return (predb.argmax(dim=1) == yb.cpu()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "5DipVlxDHjHB",
    "outputId": "5c803648-29de-4d12-fdd2-0941b342e95e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jetpacula/miniforge3/envs/firstEnv/lib/python3.9/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9540 Acc: 0.9936091303825378\n",
      "valid Loss: 0.9363 Acc: 0.975995659828186\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.9447 Acc: 0.9930424094200134\n",
      "valid Loss: 0.9339 Acc: 0.9762735366821289\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.9370 Acc: 0.9935832023620605\n",
      "valid Loss: 0.9375 Acc: 0.9761801362037659\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.9244 Acc: 0.9935427308082581\n",
      "valid Loss: 0.9030 Acc: 0.9760116338729858\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.9182 Acc: 0.993461012840271\n",
      "valid Loss: 0.9057 Acc: 0.9759831428527832\n",
      "Training complete in 50m 41s\n"
     ]
    }
   ],
   "source": [
    "loss_fn = DiceLoss()\n",
    "opt = torch.optim.Adam(unet.parameters(),lr=0.01)\n",
    "train_loss, valid_loss = train(unet,train_loader,test_loader,loss_fn,opt,acc_metric,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tb.close()\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "myPractice1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
