{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ucs08zzxJgUg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from skimage.color import rgba2rgb\n",
    "import numpy\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#раскомментируйте ниже для скачивания датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "with open('data.zip', 'wb') as f:\n",
    "    s3.download_fileobj('intelinair-data-releases', 'longitudinal-nutrient-deficiency/Longitudinal_Nutrient_Deficiency.zip', f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unzip -qq ./data.zip # распаковка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "дашборд для построения графиков и сравнения моделей / loss функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_RfHjvrNCi1",
    "outputId": "3a078454-0aa4-4593-a274-230d7fa4cc06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter # TensorBoard \n",
    "tb = SummaryWriter(comment='semantic segmentation')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "s1BPUh3WIZr0"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_labels = [x[0]+\"/nutrient_mask_g0.png\" for x in os.walk(datasetDir)][1:]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    def __getitem__(self, idx):\n",
    "        # конвертируем датасет в 3-слойное изображение\n",
    "        image = PIL.Image.open(os.path.join(datasetDir, \"field_\"+\"{:03d}\".format(idx+1)+\"/image_i0.png\")).convert('RGB') \n",
    "        #конвертируем маску в 1-слойное изображение\n",
    "        label =  PIL.Image.open(os.path.join(datasetDir, \"field_\"+\"{:03d}\".format(idx+1)+\"/nutrient_mask_g0.png\")).convert('1')\n",
    "        if self.transform:\n",
    "            image = self.transform(image) \n",
    "\n",
    "            label = self.transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tiRn0fHSDEc9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "datasetDir = os.path.join(os.getcwd(),'Longitudinal_Nutrient_Deficiency')\n",
    "mydataset = CustomDataset(img_dir = datasetDir, transform = transforms.Compose([transforms.Resize(256)\n",
    "    , transforms.CenterCrop(256),transforms.ToTensor()])) # приводим к единому размеру и конвертируем в тензор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rZvNZEXcsOAx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_data, testing_data = train_test_split(mydataset, test_size=0.2, random_state=25) #разделяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zU5w1N2WA2pv"
   },
   "outputs": [],
   "source": [
    "train_loader =  torch.utils.data.DataLoader(training_data, \n",
    "                                          batch_size=4, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1)\n",
    "    \n",
    "test_loader = torch.utils.data.DataLoader(testing_data, \n",
    "                                          batch_size=4, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train(model, train_dl, valid_dl, loss_fn, optimizer, acc_fn, epochs=20,quantizing=False):\n",
    "    start = time.time()\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_loss, valid_loss = [], []\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set trainind mode = true\n",
    "                dataloader = train_dl\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "                dataloader = valid_dl\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            step = 0            \n",
    "            for x, y in dataloader:\n",
    "                if quantizing:\n",
    "                    x = torch.quantize_per_tensor(x, 0.1, 10, torch.quint8)\n",
    "                    y = torch.quantize_per_tensor(y, 0.1, 10, torch.quint8)\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                step += 1\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(x)\n",
    "                    loss = loss_fn(outputs, y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(x)\n",
    "                        loss = loss_fn(outputs, y.long())\n",
    "                acc = acc_fn(outputs, y)\n",
    "                running_acc  += acc*dataloader.batch_size\n",
    "                running_loss += loss*dataloader.batch_size \n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_acc / len(dataloader.dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
    "    \n",
    "    return train_loss, valid_loss    \n",
    "\n",
    "def acc_metric(predb, yb):\n",
    "    return (predb.argmax(dim=1) == yb.cpu()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU метрика для сегментации \n",
    "def numpy_iou(outs,labels, threshold=0.5):\n",
    "    outs = (outs > threshold)\n",
    "    intersection = numpy.logical_and(outs.cpu().detach().numpy(), labels.cpu().detach().numpy())\n",
    "    union = numpy.logical_or(outs.cpu().detach().numpy(), labels.cpu().detach().numpy())\n",
    "    iou_score = numpy.sum(intersection) / numpy.sum(union)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b1_aa-ea7a6ee0.pth\" to /Users/jetpacula/.cache/torch/hub/checkpoints/tf_efficientnet_b1_aa-ea7a6ee0.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec96c9ef15c4ec4af3a6c59245ab878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/30.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loss-функция\n",
    "\n",
    "loss_fn = smp.losses.TverskyLoss(\"binary\", alpha=2, beta=5, gamma=5)\n",
    "\n",
    "#cnn модель\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=\"timm-efficientnet-b1\",       \n",
    "    encoder_weights=\"imagenet\",    \n",
    "    in_channels=3,                  \n",
    "    classes=1,                      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n",
      "train Loss: 0.8013 Acc: 0.10651485111477729\n",
      "valid Loss: 0.7964 Acc: 0.12140799161908825\n",
      "Epoch 1/39\n",
      "----------\n",
      "train Loss: 0.6630 Acc: 0.20370059210496813\n",
      "valid Loss: 0.6484 Acc: 0.2368250655360329\n",
      "Epoch 2/39\n",
      "----------\n",
      "train Loss: 0.5801 Acc: 0.2558309608335729\n",
      "valid Loss: 0.6544 Acc: 0.23703402071290022\n",
      "Epoch 3/39\n",
      "----------\n",
      "train Loss: 0.5794 Acc: 0.2540230909421032\n",
      "valid Loss: 0.6188 Acc: 0.23128203962235716\n",
      "Epoch 4/39\n",
      "----------\n",
      "train Loss: 0.5185 Acc: 0.29033301695045066\n",
      "valid Loss: 0.6177 Acc: 0.2431184075349488\n",
      "Epoch 5/39\n",
      "----------\n",
      "train Loss: 0.5109 Acc: 0.2964637989442065\n",
      "valid Loss: 0.5687 Acc: 0.2772141132291425\n",
      "Epoch 6/39\n",
      "----------\n",
      "train Loss: 0.5035 Acc: 0.3044126507848323\n",
      "valid Loss: 0.6212 Acc: 0.24524277255591542\n",
      "Epoch 7/39\n",
      "----------\n",
      "train Loss: 0.4867 Acc: 0.3116847165982451\n",
      "valid Loss: 0.6748 Acc: 0.22703487578205683\n",
      "Epoch 8/39\n",
      "----------\n",
      "train Loss: 0.4817 Acc: 0.3257985892759814\n",
      "valid Loss: 0.6002 Acc: 0.25020288751281655\n",
      "Epoch 9/39\n",
      "----------\n",
      "train Loss: 0.4556 Acc: 0.3365488409111048\n",
      "valid Loss: 0.5727 Acc: 0.2611787648577086\n",
      "Epoch 10/39\n",
      "----------\n",
      "train Loss: 0.4850 Acc: 0.3144328290331752\n",
      "valid Loss: 0.6137 Acc: 0.2761894183740085\n",
      "Epoch 11/39\n",
      "----------\n",
      "train Loss: 0.4546 Acc: 0.3385338065319102\n",
      "valid Loss: 0.6010 Acc: 0.2797768210032121\n",
      "Epoch 12/39\n",
      "----------\n",
      "train Loss: 0.4145 Acc: 0.36427224329248065\n",
      "valid Loss: 0.5990 Acc: 0.2743126940204098\n",
      "Epoch 13/39\n",
      "----------\n",
      "train Loss: 0.4324 Acc: 0.35461439016479696\n",
      "valid Loss: 0.5652 Acc: 0.2779924200940558\n",
      "Epoch 14/39\n",
      "----------\n",
      "train Loss: 0.4272 Acc: 0.3556715097680962\n",
      "valid Loss: 0.5968 Acc: 0.26855028193380703\n",
      "Epoch 15/39\n",
      "----------\n",
      "train Loss: 0.3975 Acc: 0.38083282976557026\n",
      "valid Loss: 0.5554 Acc: 0.2944831102424075\n",
      "Epoch 16/39\n",
      "----------\n",
      "train Loss: 0.3977 Acc: 0.3778939137414737\n",
      "valid Loss: 0.6340 Acc: 0.26192028164330333\n",
      "Epoch 17/39\n",
      "----------\n",
      "train Loss: 0.3546 Acc: 0.4094126680083824\n",
      "valid Loss: 0.5777 Acc: 0.2822094196016919\n",
      "Epoch 18/39\n",
      "----------\n",
      "train Loss: 0.3753 Acc: 0.3999706944100779\n",
      "valid Loss: 0.5871 Acc: 0.2608839699201814\n",
      "Epoch 19/39\n",
      "----------\n",
      "train Loss: 0.3582 Acc: 0.40755101311859837\n",
      "valid Loss: 0.5865 Acc: 0.29020740260499994\n",
      "Epoch 20/39\n",
      "----------\n",
      "train Loss: 0.3408 Acc: 0.42292409266330233\n",
      "valid Loss: 0.5546 Acc: 0.31617926476044533\n",
      "Epoch 21/39\n",
      "----------\n",
      "train Loss: 0.3225 Acc: 0.43668691779352425\n",
      "valid Loss: 0.5516 Acc: 0.2629503779212149\n",
      "Epoch 22/39\n",
      "----------\n",
      "train Loss: 0.3402 Acc: 0.41861637663311363\n",
      "valid Loss: 0.6430 Acc: 0.27338866133562606\n",
      "Epoch 23/39\n",
      "----------\n",
      "train Loss: 0.3151 Acc: 0.4424857621201406\n",
      "valid Loss: 0.6263 Acc: 0.25749070560244086\n",
      "Epoch 24/39\n",
      "----------\n",
      "train Loss: 0.3187 Acc: 0.4373934954209296\n",
      "valid Loss: 0.6581 Acc: 0.2520322731195216\n",
      "Epoch 25/39\n",
      "----------\n",
      "train Loss: 0.3073 Acc: 0.44800224762530544\n",
      "valid Loss: 0.5898 Acc: 0.28690068744206326\n",
      "Epoch 26/39\n",
      "----------\n",
      "train Loss: 0.3000 Acc: 0.4520538046837565\n",
      "valid Loss: 0.5933 Acc: 0.28647862267546675\n",
      "Epoch 27/39\n",
      "----------\n",
      "train Loss: 0.2925 Acc: 0.4617583777680123\n",
      "valid Loss: 0.6050 Acc: 0.28336285687412555\n",
      "Epoch 28/39\n",
      "----------\n",
      "train Loss: 0.2880 Acc: 0.4573072309521983\n",
      "valid Loss: 0.6196 Acc: 0.2851168657630861\n",
      "Epoch 29/39\n",
      "----------\n",
      "train Loss: 0.2723 Acc: 0.4758189488406963\n",
      "valid Loss: 0.6281 Acc: 0.26198782457527325\n",
      "Epoch 30/39\n",
      "----------\n",
      "train Loss: 0.2708 Acc: 0.47991575558591965\n",
      "valid Loss: 0.5740 Acc: 0.2878158847673965\n",
      "Epoch 31/39\n",
      "----------\n",
      "train Loss: 0.2737 Acc: 0.47037666820336355\n",
      "valid Loss: 0.5926 Acc: 0.2827735108485596\n",
      "Epoch 32/39\n",
      "----------\n",
      "train Loss: 0.2535 Acc: 0.4879591982607421\n",
      "valid Loss: 0.6039 Acc: 0.27227362482941986\n",
      "Epoch 33/39\n",
      "----------\n",
      "train Loss: 0.2450 Acc: 0.49724371257586775\n",
      "valid Loss: 0.6406 Acc: 0.2689997564370131\n",
      "Epoch 34/39\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# оптимизатор\n",
    "opt = torch.optim.AdamW(model.parameters(),lr=0.001) \n",
    "\n",
    "#обучаем модель\n",
    "train_loss, valid_loss = train(model,train_loader,test_loader,loss_fn,opt,numpy_iou,epochs=40,quantizing=False)\n",
    "torch.save(model.state_dict(), \"tversky_loss_SMOL_40_epochs_iou_DeepLab_NOTquantized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = \"qnnpack\" # драйвер для статической квантизации\n",
    "model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.backends.quantized.engine = backend\n",
    "model_static_quantized = torch.quantization.prepare(model, inplace=False) \n",
    "model_static_quantized = torch.quantization.convert(model_static_quantized, inplace=False)\n",
    "\n",
    "torch.save(model_static_quantized.state_dict(), \"tversky_loss_SMOL_40_epochs_iou_DeepLab_NOTquantized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.close()\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original model size\n",
      "30.12 MB\n",
      "quantized model size\n",
      "8.37 MB\n"
     ]
    }
   ],
   "source": [
    "#сравниваем размер квантизованной / неквантизованной модели\n",
    "\n",
    "def print_model_size(mdl):\n",
    "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
    "    print(\"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
    "    os.remove('tmp.pt')\n",
    "print('original model size')\n",
    "print_model_size(model)\n",
    "print('quantized model size')\n",
    "print_model_size(model_static_quantized)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "myPractice1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
